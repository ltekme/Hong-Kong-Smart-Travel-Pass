{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain \n",
    "%pip install langchain_chroma \n",
    "%pip install langchain_community \n",
    "%pip install langchain_core\n",
    "%pip install langchain_google_vertexai\n",
    "%pip install langchain_text_splitters\n",
    "%pip install jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = DirectoryLoader('docs2', glob='**/*.htm', loader_cls=BSHTMLLoader, loader_kwargs={'open_encoding': 'utf8'}, show_progress=True, use_multithreading=True)\n",
    "\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# model = 'Alibaba-NLP/gte-large-en-v1.5'\n",
    "# model_kwargs = model_kwargs = {'device':'cpu', 'trust_remote_code': True}\n",
    "# encode_kwargs = {'normalize_embeddings': True}\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=model,\n",
    "#     model_kwargs=model_kwargs,\n",
    "#     encode_kwargs=encode_kwargs\n",
    "# )\n",
    "\n",
    "# vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_community.document_loaders as document_loaders\n",
    "kmb_loader = document_loaders.JSONLoader('./bus_cleaned.json', jq_schema=\".features\", text_content=False)\n",
    "kmb_loaded = kmb_loader.load()\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [114.192446, 22.345353]}, 'properties': {'routeId': 1001, 'companyCode': 'KMB', 'district': '', 'routeNameC': '1', 'routeNameS': '1', 'routeNameE': '1', 'routeType': 1, 'serviceMode': 'R', 'specialType': 0, 'journeyTime': 49, 'locStartNameC': '竹園邨', 'locStartNameS': '竹园邨', 'locStartNameE': 'CHUK YUEN ESTATE', 'locEndNameC': '尖沙咀碼頭', 'locEndNameS': '尖沙咀码头', 'locEndNameE': 'STAR FERRY', 'hyperlinkC': 'https://search.kmb.hk/KMBWebSite/?action=routesearch&route=1&lang=zh-hk', 'hyperlinkS': 'https://search.kmb.hk/KMBWebSite/?action=routesearch&route=1&lang=zh-cn', 'hyperlinkE': 'https://search.kmb.hk/KMBWebSite/?action=routesearch&route=1&lang=en', 'fullFare': 6.4, 'lastUpdateDate': '2023-07-07T00:00:00', 'routeSeq': 1, 'stopSeq': 1, 'stopId': 4001, 'stopPickDrop': 2, 'stopNameC': '竹園邨總站', 'stopNameS': '竹园邨总站', 'stopNameE': 'CHUK YUEN ESTATE BUS TERMINUS'}}, {'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates':\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(kmb_loaded)\n",
    "splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide into chunks for Chroma add document\n",
    "def divide_chunks(l, n):\n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]\n",
    "\n",
    "chunks = list(divide_chunks(splits, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import FakeEmbeddings\n",
    "fakeEmbeddings = FakeEmbeddings(\n",
    "    size=764\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vertex_store = Chroma(\n",
    "    collection_name='KMB',\n",
    "    embedding_function=fakeEmbeddings,\n",
    "    persist_directory='./chroma_db_fake',\n",
    ")\n",
    "\n",
    "for c, i in enumerate(chunks[0:10]):\n",
    "    print(vertex_store.add_documents(i))\n",
    "    print(f\"Added {c+1} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeEmbeddings.embed_query('1001')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
