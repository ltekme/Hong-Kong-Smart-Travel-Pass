{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain \n",
    "%pip install langchain_chroma \n",
    "%pip install langchain_community \n",
    "%pip install langchain_core\n",
    "%pip install langchain_google_vertexai\n",
    "%pip install langchain_text_splitters\n",
    "%pip install jq\n",
    "# %pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bs4\n",
    "# from langchain import hub\n",
    "# from langchain_chroma import Chroma\n",
    "# from langchain_community.document_loaders import WebBaseLoader\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.runnables import RunnablePassthrough\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "# # Load, chunk and index the contents of the blog.\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# splits = text_splitter.split_documents(docs)\n",
    "# vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "# # Retrieve and generate using the relevant snippets of the blog.\n",
    "# retriever = vectorstore.as_retriever()\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# def format_docs(docs):\n",
    "#     return \"\\n\\n\".join(doc for doc in docs)\n",
    "\n",
    "\n",
    "# rag_chain = (\n",
    "#     {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "#     | prompt\n",
    "#     | llm\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "\n",
    "# rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "credentials = Credentials.from_service_account_file(\n",
    "    \"ive-fyp-436703-3a208c6d96a0.json\")\n",
    "\n",
    "vertexAIEmbeddings = VertexAIEmbeddings(\n",
    "        credentials=credentials,\n",
    "        project=credentials.project_id,\n",
    "        model_name=\"text-multilingual-embedding-002\",\n",
    "    )\n",
    "\n",
    "vectorstore = Chroma(persist_directory='./chroma_db', embedding_function=vertexAIEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karlc\\AppData\\Roaming\\Python\\Python312\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "credentials=Credentials.from_service_account_file(\"ive-fyp-436703-3a208c6d96a0.json\")\n",
    "\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-1.0-pro\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    credentials=credentials,\n",
    "    project=credentials.project_id,\n",
    "    task=\"text-generation\",\n",
    "    region=\"us-central1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but the provided context does not contain information about the routes available at AMOY GARDENS station. Therefore, I cannot answer your question. \\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What routes from KMB are avalable at AMOY GARDENS station?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"AMOY GARDENS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
